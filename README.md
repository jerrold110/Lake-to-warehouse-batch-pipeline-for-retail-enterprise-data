# Lake to warehouse batch pipeline for retail enterprise data

#### Run this project
```
docker compose up -d
./setup.sh

# Spark UI: localhost:8080
# Airflow Webserver: localhost:8081
```

## The data
### Data flow diagram
### Dag, steps in each task, and daily pipeline timeline
### Source (Lake)
### Sink (Warehouse)

## The Pipeline
### Spark and AWS
### Replayability, Overwritability, and Idempotency


